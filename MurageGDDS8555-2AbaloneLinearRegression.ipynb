{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25578bc5-7454-4001-883e-9384dcc7d504",
   "metadata": {},
   "source": [
    "<BR>\n",
    "<BR>\n",
    "<BR>\n",
    "<BR>\n",
    "<BR>\n",
    "<BR>\n",
    "   \n",
    "                                          \n",
    "                                          \n",
    "                                          \n",
    "                                          \n",
    "                                          \n",
    "#                                                 Regression with Abalone Data Set: Linear Regression Model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##                                                       Gladys Murage\n",
    "\n",
    "##              College of Business, Engineering, and  Technology, National University\n",
    "\n",
    "##                                         DDS8555 v1: PREDICTIVE ANALYSIS(3602869492)\n",
    "\n",
    "##                                                        Dr MOHAMED NABEEL\n",
    "\n",
    "##                                                            March 06, 2025\n",
    "\n",
    "\n",
    "<BR>\n",
    "<BR>\n",
    "<BR>\n",
    "<BR>\n",
    "<BR>\n",
    "<BR>\n",
    "<BR>\n",
    "<BR>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f678c744-a71c-4ec4-a13f-86c0eee269c1",
   "metadata": {},
   "source": [
    "# 1. Linear Regression Model\n",
    "This code performs a linear regression task on a dataset to predict a target variable (Rings in this case) and evaluates the model using the Root Mean Squared Logarithmic Error (RMSLE). It also prepares a submission file for predictions on the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7ad1543a-38cb-4cd7-88ea-15e4211b4710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:\n",
      "   id Sex  Length  Diameter  Height  Whole weight  Whole weight.1  \\\n",
      "0   0   F   0.550     0.430   0.150        0.7715          0.3285   \n",
      "1   1   F   0.630     0.490   0.145        1.1300          0.4580   \n",
      "2   2   I   0.160     0.110   0.025        0.0210          0.0055   \n",
      "3   3   M   0.595     0.475   0.150        0.9145          0.3755   \n",
      "4   4   I   0.555     0.425   0.130        0.7820          0.3695   \n",
      "\n",
      "   Whole weight.2  Shell weight  Rings  \n",
      "0          0.1465        0.2400     11  \n",
      "1          0.2765        0.3200     11  \n",
      "2          0.0030        0.0050      6  \n",
      "3          0.2055        0.2500     10  \n",
      "4          0.1600        0.1975      9  \n",
      "\n",
      "Test Data:\n",
      "      id Sex  Length  Diameter  Height  Whole weight  Whole weight.1  \\\n",
      "0  90615   M   0.645     0.475   0.155        1.2380          0.6185   \n",
      "1  90616   M   0.580     0.460   0.160        0.9830          0.4785   \n",
      "2  90617   M   0.560     0.420   0.140        0.8395          0.3525   \n",
      "3  90618   M   0.570     0.490   0.145        0.8740          0.3525   \n",
      "4  90619   I   0.415     0.325   0.110        0.3580          0.1575   \n",
      "\n",
      "   Whole weight.2  Shell weight  \n",
      "0          0.3125        0.3005  \n",
      "1          0.2195        0.2750  \n",
      "2          0.1845        0.2405  \n",
      "3          0.1865        0.2350  \n",
      "4          0.0670        0.1050  \n",
      "\n",
      "Sample Submission:\n",
      "      id  Rings\n",
      "0  90615     10\n",
      "1  90616     10\n",
      "2  90617     10\n",
      "3  90618     10\n",
      "4  90619     10\n",
      "\n",
      "Train Data Columns: Index(['id', 'Sex', 'Length', 'Diameter', 'Height', 'Whole weight',\n",
      "       'Whole weight.1', 'Whole weight.2', 'Shell weight', 'Rings'],\n",
      "      dtype='object')\n",
      "Train Data Types:\n",
      " id                  int64\n",
      "Sex                object\n",
      "Length            float64\n",
      "Diameter          float64\n",
      "Height            float64\n",
      "Whole weight      float64\n",
      "Whole weight.1    float64\n",
      "Whole weight.2    float64\n",
      "Shell weight      float64\n",
      "Rings               int64\n",
      "dtype: object\n",
      "Validation RMSLE: 0.16678492724006372\n",
      "Submission file saved as 'submission.csv'\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the datasets\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "sample_submission = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "# Display the first few rows of each dataset\n",
    "print(\"Train Data:\")\n",
    "print(train_data.head())\n",
    "\n",
    "print(\"\\nTest Data:\")\n",
    "print(test_data.head())\n",
    "\n",
    "print(\"\\nSample Submission:\")\n",
    "print(sample_submission.head())\n",
    "\n",
    "# Check column names and data types\n",
    "print(\"\\nTrain Data Columns:\", train_data.columns)\n",
    "print(\"Train Data Types:\\n\", train_data.dtypes)\n",
    "\n",
    "# Preprocess the data\n",
    "# Handle missing values (if any)\n",
    "train_data = train_data.dropna()\n",
    "test_data = test_data.dropna()\n",
    "\n",
    "# Replace \"target_column\" with the actual target column name in this care \"Rings\"\n",
    "target_column = \"Rings\"  \n",
    "# Strip column names to remove extra spaces\n",
    "train_data.columns = train_data.columns.str.strip()\n",
    "test_data.columns = test_data.columns.str.strip()\n",
    "\n",
    "# Encode categorical variables (e.g., 'Sex') in this case\n",
    "categorical_columns = [\"Sex\"]  \n",
    "for col in categorical_columns:\n",
    "    if col not in train_data.columns:\n",
    "        raise ValueError(f\"Column '{col}' not found in the dataset.\")\n",
    "\n",
    "train_data = pd.get_dummies(train_data, columns=categorical_columns, drop_first=True)\n",
    "test_data = pd.get_dummies(test_data, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Ensure train and test data have the same columns\n",
    "train_data, test_data = train_data.align(test_data, join='outer', axis=1, fill_value=0)\n",
    "\n",
    "# Separate features (X) and target (y) in the training data\n",
    "X = train_data.drop(columns=[target_column])\n",
    "y = train_data[target_column]\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the numeric features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Initialize and train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = model.predict(X_val_scaled)\n",
    "\n",
    "# Clip negative predictions to zero\n",
    "y_val_pred = np.maximum(y_val_pred, 0)\n",
    "\n",
    "# Calculate RMSLE\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "\n",
    "rmsle_val = rmsle(y_val, y_val_pred)\n",
    "print(\"Validation RMSLE:\", rmsle_val)\n",
    "\n",
    "# Preprocess the test data\n",
    "X_test = test_data.drop(columns=[target_column])\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Clip negative predictions to zero\n",
    "y_test_pred = np.maximum(y_test_pred, 0)\n",
    "\n",
    "# Prepare the submission file\n",
    "sample_submission[target_column] = y_test_pred\n",
    "sample_submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"Submission file saved as 'submission.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be70b66-750d-4738-a92b-2a1e53d51ae7",
   "metadata": {},
   "source": [
    "# 2. Verify the Submission File\r\n",
    "Ensure the submission file matches the format of the sample submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "39800822-0f05-4f45-98a4-4368bae15c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id      Rings\n",
      "0  90615   8.511788\n",
      "1  90616  10.006078\n",
      "2  90617  10.282228\n",
      "3  90618  10.932569\n",
      "4  90619   7.759140\n"
     ]
    }
   ],
   "source": [
    "# Print the top 5 records\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d328a17b-4ac8-4c91-a443-8ba1c15e2482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id      Rings\n",
      "60406  151021   6.610125\n",
      "60407  151022   9.199089\n",
      "60408  151023  10.789541\n",
      "60409  151024  13.520669\n",
      "60410  151025   8.570570\n"
     ]
    }
   ],
   "source": [
    "# Print the last 5 records\n",
    "print(submission.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "99508299-a4a1-4a8f-9c8a-fe377f290c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of submission file: (60411, 2)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of the submission DataFrame\n",
    "print(\"Shape of submission file:\", submission.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d210a777-6f74-43b1-8229-4cbd0ae7dc3c",
   "metadata": {},
   "source": [
    "# 3. Evaluate the Model \n",
    "If one has  access to the true target values for the test data (e.g., in a competition), you can evaluate the model's performance using metrics like Mean Squared Error (MSE) or R-squared (R²). However, in this Kaggle competition  the goal is to predict the age of abalone using various physical measurements. The evaluation metric for this competition is Root Mean Squared Logarithmic Error (RMSLE). The target feature is Rings.\n",
    "## Key things to note:\n",
    "1. Clip Predictions: ensure predictions are non-negative before applying the logarithm, as log(0) or log(negative) is undefined.\n",
    "2. Logarithmic Transformation: RMSLE uses log1p (log of 1 + value) to handle zero values well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d673bc6-3fc8-4fe7-bdc5-ac46f8686b25",
   "metadata": {},
   "source": [
    "# 4.  Interpretation of the RMSLE Value\n",
    "The Validation RMSLE (Root Mean Squared Logarithmic Error) value of 0.1668 is a measure of how well the regression model is performing on the validation (test) set. The interpretation of this RMSLE  value is as follows:\n",
    "## What is RMSLE?\n",
    "RMSLE is a metric used to evaluate regression models, especially when the target variable has a wide range of values or is skewed. It measures the difference between the predicted and actual values on a logarithmic scale.\n",
    "\n",
    "## Interpretation of RMSLE = 0.1668\n",
    "A lower RMSLE is better: RMSLE is a non-negative metric, and a value of 0 would indicate perfect predictions. A smaller RMSLE indicates better model performance.\n",
    "\n",
    "Scale of RMSLE: RMSLE is on a logarithmic scale, so the interpretation depends on the context of the  data. However, in general:\n",
    "\n",
    "RMSLE < 0.1: indicates very good model performance.\n",
    "\n",
    "RMSLE between 0.1 and 0 : indicates decent performance but may need improvement.\n",
    "\n",
    "RMSLE > 0.2: indicates poor performance and significant room for improvement.\n",
    "\n",
    "The obtained resulting RMSLE (0.1668) is a moderate value, indicating that the regression model is performing decently on the validation set. The predictions are not close to the actual values on a logarithmic scale. Model improvement is called for.\n",
    "\n",
    "RMSLE is scale-independent: it is less sensitive to large outliers compared to RMSE.\n",
    "\n",
    "RMSLE penalizes underestimates more than overestimates due to the logarithmic transformation.\n",
    "## What Does RMSLE = 0.1668 Mean?\n",
    "Logarithmic Scale: RMSLE measures the relative error between the predicted and actual values on a logarithmic scale. A value of 0.1668 means that, on average, the logarithmic difference between the predicted and actual values is 0.1668.\n",
    "\n",
    "Relative Error: RMSLE is less sensitive to large outliers compared to RMSE (Root Mean Squared Error), so it focuses more on the relative error rather than the absolute error. This makes it a good metric for datasets where the target variable spans a wide range or is skewed.\n",
    "\n",
    "## Context of the regression  Model:\n",
    "Decent Performance: an RMSLE of 0.1668 suggests that the model is performing reasonably well but is not yet optimal. It is making predictions that are somewhat close to the true values, but there is still room for improvement.\n",
    "\n",
    "Potential Overfitting or Underfitting: If the training RMSLE is much lower than the validation RMSLE, your model might be overfitting. If both are high, the model might be underfitting.\n",
    "## Why is the RMSLE = 0.1668?\n",
    "Here are some potential reasons for this RMSLE value:\n",
    "\n",
    "## Model-Related Issues\n",
    "### Underfitting:\n",
    "\n",
    "The model might be too simple in this case; Linear Regression to capture the underlying patterns in the data.\n",
    "\n",
    "Solution: to apply more complex models like Random Forest, Gradient Boosting, XGBoost, LightGBM, or Neural Networks.\n",
    "\n",
    "### Overfitting:\n",
    "\n",
    "The model might be too complex and is memorizing the training data instead of generalizing to unseen data.\n",
    "\n",
    "Solution: Use regularization techniques (e.g., L1/L2 regularization) or simplify the model.\n",
    "\n",
    "Poor Feature Engineering:\n",
    "\n",
    "The features used might not be sufficiently informative or might need transformation (e.g., log transformation, polynomial features).\n",
    "\n",
    "Solution: Perform feature engineering to create more meaningful features.\n",
    "\n",
    "### Hyperparameter Tuning:\n",
    "\n",
    "The model's hyperparameters might not be optimized.\n",
    "\n",
    "Solution: use techniques like Grid Search or Random Search to find the best hyperparameters.\n",
    "\n",
    "## Data-Related Issues\n",
    "### Outliers:\n",
    "\n",
    "Outliers in the target variable can skew the model's predictions.\n",
    "\n",
    "Solution: identify and handle outliers (e.g., clipping, transformation).\n",
    "\n",
    "### Skewed Target Variable:\n",
    "\n",
    "If the target variable (Rings) is highly skewed, the model might struggle to predict extreme values accurately.\n",
    "\n",
    "Solution: apply a log transformation to the target variable to reduce skewness.\n",
    "\n",
    "### Missing Values:\n",
    "\n",
    "Missing values in the features or target variable can affect model performance.\n",
    "\n",
    "Solution: handle missing values (e.g., imputation, removal).\n",
    "\n",
    "### Insufficient Data:\n",
    "\n",
    "If the dataset is small, the model might not have enough data to learn effectively.\n",
    "\n",
    "Solution: collect more data or use data augmentation techniques.\n",
    "## Next Steps\n",
    "Check for overfitting to ensure that the model is not overfitting the training data. A comparison of the training RMSLE and validation RMSLE will be conducted. If the training RMSLE is much lower than the validation RMSLE, the model may be overfitting.\n",
    "\n",
    "Test Set Evaluation: since there is a separate test data set, I will evaluate the model to confirm its performance on completely unseen data.\n",
    "\n",
    "Model Improvement: in order to further improve the model, I would consider the following:\n",
    "\n",
    "Feature engineering.\n",
    "\n",
    "Hyperparameter tuning.\n",
    "\n",
    "Trying more advanced models e.g., Random Forest and  Gradient Boosting. I will conduct both."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaa7173-24bf-4d5f-b69d-f3d8e40aa68b",
   "metadata": {},
   "source": [
    "# 5. Comparing Training and Validation RMSLE\n",
    "To check for overfitting, calculate the RMSLE on the training set and compare it to the validation RMSLE\n",
    "## How to Improve the Model\n",
    "Step 1: Compare Training and Validation RMSLE\n",
    "Check if the model is overfitting or underfitting by comparing the training and validation RMSLE:\n",
    "\n",
    "If Training RMSLE << Validation RMSLE: The model is overfitting.\n",
    "\n",
    "If Training RMSLE ≈ Validation RMSLE: The model is underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f1a29778-9e3c-4201-a8d0-b11770579ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSLE: 0.1624395498468596\n",
      "Validation RMSLE: 0.16491523791503435\n"
     ]
    }
   ],
   "source": [
    "# Import library\n",
    "import numpy as np\n",
    "\n",
    "def rmsle(y_true, y_pred):\n",
    "    # Ensure there are no non-positive values in y_true and y_pred\n",
    "    mask = (y_pred > 0) & (y_true > 0)\n",
    "    y_true_filtered = y_true[mask]\n",
    "    y_pred_filtered = y_pred[mask]\n",
    "    \n",
    "    # Calculate the RMSLE\n",
    "    return np.sqrt(np.mean(np.power(np.log1p(y_pred_filtered) - np.log1p(y_true_filtered), 2)))\n",
    "\n",
    "# Calculate and print metrics using the new RMSLE function\n",
    "train_rmsle = rmsle(y_train, y_train_pred)\n",
    "val_rmsle = rmsle(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Training RMSLE: {train_rmsle}\")\n",
    "print(f\"Validation RMSLE: {val_rmsle}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cac6efa-0daf-4d31-8417-e853551cade4",
   "metadata": {},
   "source": [
    "# Comparison of Training and Validation RMSLE results:\n",
    "Training RMSLE ≈ Validation RMSLE: The training and validation RMSLE values are very close, which suggests that the model is generalizing well and is not overfitting or underfitting significantly.\n",
    "\n",
    "## Small Gap: \n",
    "The small difference between the two values (0.1624 vs. 0.1649) indicates that the model is performing consistently on both the training and validation sets.\n",
    "\n",
    "## What Does this Mean for the linear regression Model?\n",
    "Good Generalization: the model is not overfitting (memorizing the training data) or underfitting (failing to capture patterns in the data). It is performing well on both the training and validation sets.\n",
    "\n",
    "Consistent Performance: the small gap between the training and validation RMSLE suggests that the model is robust and reliable.\n",
    "\n",
    "Room for Improvement: while the model is performing well, there is still room to improve the RMSLE further. An RMSLE of 0.1649 is decent but not optimal. This model is most likely underfitting.\n",
    "## How to Improve the Model\n",
    "Step 1: try a More Complex Model\n",
    "If the model is underfitting, try a more complex model like Random Forest, Gradient Boosting, or XGBoost. I will attempt a random forest and if that still does not differentiate the RMSLE I will create an XG Boost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc96be8-7ed6-4f58-b07a-c5e3af3d9a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2024.02-py310",
   "language": "python",
   "name": "conda-env-anaconda-2024.02-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
